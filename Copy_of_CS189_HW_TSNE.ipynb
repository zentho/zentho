{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zentho/zentho/blob/main/Copy_of_CS189_HW_TSNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxYASTXBDVc3"
      },
      "source": [
        "# CS 189 Homework 4 T-SNE\n",
        "**Note:** before starting this notebook, please save a copy of it to your own google drive, or your changes will not persist.\n",
        "\n",
        "In this problem, you will explore one way in which an ML engineer might try to interpret what the neural network they have just trained is doing. It turns out that t-SNE can come in handy here not just as a data visualization tool, but also as a *feature* visualization tool. Neural nets are, after all, trying to learn good features of the data for prediction.\n",
        "\n",
        "You will use scikit-learn's TSNE functionality for this problem, so it would be a good idea to look at that documentation. Your deliverables will be your code in this notebook as well as all plots that you produce here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qoJVI0RCyaH"
      },
      "source": [
        "# Imports for pytorch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import tqdm.notebook as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0gXlpSfT2A7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmwd_kzNT-Cq"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "          [torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "batch_size = 4\n",
        "trainloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feel free to visualize the data to get a sense of what the dataset looks like (note that the images have been normalized):"
      ],
      "metadata": {
        "id": "xY7rDFcg3og6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = [training_data[i][0] for i in range(9)]\n",
        "plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1, 2, 0)))"
      ],
      "metadata": {
        "id": "6PNE-4LT3lx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part (a): Take the first 1000 images in the training dataset and perform t-SNE on the flattened images. Plot the t-SNE embeddings and color-code them by the class of each data point."
      ],
      "metadata": {
        "id": "mLDGeLcwK-IH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4DyQNjKjlol"
      },
      "source": [
        "### Part (a) ###\n",
        "### YOUR CODE HERE ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part (b): Find the test accuracy of the neural network provided.\n",
        "\n"
      ],
      "metadata": {
        "id": "PLhDxz5OOS9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 128, 3, 1, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "        self.conv2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.linear1 = nn.Linear(256 * 16 * 16, 256)\n",
        "        self.bn_l1 = nn.BatchNorm1d(256)\n",
        "        self.linear2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Loading model\n",
        "net = Net().to(device)\n",
        "model_save_name = 'cifar10_classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" # Change path as necessary!\n",
        "net = torch.load(path)\n",
        "net.eval()"
      ],
      "metadata": {
        "id": "pJ32DyOT3NKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Part (b) ###\n",
        "### YOUR CODE HERE ###\n"
      ],
      "metadata": {
        "id": "YZWMwUt6v116"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part (c): For the following parts, we will make use of *hook* functions to save the outputs of particular layers of the model during a forward pass. We have provided a function below describing its usage. Use the function to obtain the set of outputs from net.conv3 for the first 1000 images of the training dataset as inputs. Then, run t-SNE on those outputs. Plot the t-SNE embeddings and color-code them by the class of each data point.\n",
        "\n",
        "For reference, the neural network layers are: \\\\\n",
        "net.conv1 \\\\\n",
        "net.conv2 \\\\\n",
        "net.conv3 \\\\\n",
        "net.linear1 \\\\\n",
        "net.linear2 \\\\"
      ],
      "metadata": {
        "id": "e-mYYEb-OyOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "     features=None\n",
        "     def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
        "     def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy()\n",
        "     def remove(self): self.hook.remove()"
      ],
      "metadata": {
        "id": "A3GsVQfwz9kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: get_features_from_layer(net.conv1)\n",
        "def get_features_from_layer(layer):\n",
        "  activated_features = SaveFeatures(layer)\n",
        "  return activated_features"
      ],
      "metadata": {
        "id": "IXnR0mopQmo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Part (c) ###\n",
        "### YOUR CODE HERE ###\n",
        "## Hint: Call get_features_from_layer() and use the 'features' attribute of the SaveFeatures class\n"
      ],
      "metadata": {
        "id": "Ibj0WmYe0Egj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part (d): Do the same as part (c) except for the first and second linear layers of the network."
      ],
      "metadata": {
        "id": "ZKlwILWddvHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Part (d) ###\n",
        "### YOUR CODE HERE ###\n"
      ],
      "metadata": {
        "id": "knjbrFnGeDGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofNTv8Z57x1w"
      },
      "source": [
        "Congrats! You made it to the end."
      ]
    }
  ]
}